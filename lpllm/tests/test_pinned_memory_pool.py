#!/usr/bin/env python3
"""
Comprehensive test suite for PinnedMemoryPool
æµ‹è¯•PinnedMemoryPoolçš„å„ç§åŠŸèƒ½å’Œè¾¹ç•Œæƒ…å†µ
"""

import torch
import time
import threading
import random
import gc
from typing import List, Tuple
from lpllm.pinpool import PinnedMemoryPool, PreAllocatedPinnedMemoryPool, HybridPinnedMemoryPool


def test_basic_allocation():
    """æµ‹è¯•åŸºæœ¬å†…å­˜åˆ†é…å’Œé‡Šæ”¾åŠŸèƒ½"""
    print("=== æµ‹è¯•åŸºæœ¬å†…å­˜åˆ†é…åŠŸèƒ½ ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=2)
    print(f"åˆå§‹çŠ¶æ€: {pool.get_usage_info()}")

    # åˆ†é…ä¸åŒå¤§å°çš„å†…å­˜å—
    tensors = []
    sizes = [100, 200, 300, 400]  # MB

    for i, size_mb in enumerate(sizes):
        tensor = pool.alloc(size_mb)
        tensors.append((tensor, size_mb))
        print(f"åˆ†é… {size_mb}MB: {tensor.shape}")
        print(f"çŠ¶æ€: {pool.get_usage_info()}")

    # é‡Šæ”¾å†…å­˜å—
    for i, (tensor, size_mb) in enumerate(tensors):
        pool.free(tensor)
        print(f"é‡Šæ”¾ {size_mb}MB")
        print(f"çŠ¶æ€: {pool.get_usage_info()}")

    print("âœ… åŸºæœ¬åˆ†é…æµ‹è¯•é€šè¿‡\n")


def test_chunk_boundary():
    """æµ‹è¯•chunkè¾¹ç•Œæƒ…å†µ"""
    print("=== æµ‹è¯•chunkè¾¹ç•Œæƒ…å†µ ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=2)

    # æµ‹è¯•åˆ†é…æ¥è¿‘chunkå¤§å°çš„å†…å­˜
    large_tensor = pool.alloc(900)  # 900MB < 1024MB
    print(f"åˆ†é…900MB: {large_tensor.shape}")
    print(f"çŠ¶æ€: {pool.get_usage_info()}")

    # æµ‹è¯•åˆ†é…è¶…è¿‡chunkå¤§å°çš„å†…å­˜ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
    try:
        too_large = pool.alloc(1200)  # 1200MB > 1024MB
        print("âŒ é”™è¯¯ï¼šåº”è¯¥æ‹’ç»è¶…è¿‡chunkå¤§å°çš„åˆ†é…")
    except MemoryError:
        print("âœ… æ­£ç¡®æ‹’ç»äº†è¶…è¿‡chunkå¤§å°çš„åˆ†é…")

    pool.free(large_tensor)
    print("âœ… Chunkè¾¹ç•Œæµ‹è¯•é€šè¿‡\n")


def test_fragmentation():
    """æµ‹è¯•å†…å­˜ç¢ç‰‡åŒ–æƒ…å†µ"""
    print("=== æµ‹è¯•å†…å­˜ç¢ç‰‡åŒ– ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=3)

    # åˆ›å»ºä¸€äº›ç¢ç‰‡
    tensors = []
    for i in range(5):
        size_mb = random.randint(50, 200)
        tensor = pool.alloc(size_mb)
        tensors.append((tensor, size_mb))

    print(f"åˆ†é…åçŠ¶æ€: {pool.get_usage_info()}")

    # éšæœºé‡Šæ”¾ä¸€äº›tensor
    for i in [0, 2, 4]:
        tensor, size_mb = tensors[i]
        pool.free(tensor)
        print(f"é‡Šæ”¾tensor {i}: {size_mb}MB")

    print(f"éƒ¨åˆ†é‡Šæ”¾åçŠ¶æ€: {pool.get_usage_info()}")

    # å°è¯•é‡æ–°åˆ†é…
    new_tensor = pool.alloc(150)
    print(f"é‡æ–°åˆ†é…150MB: {new_tensor.shape}")
    print(f"æœ€ç»ˆçŠ¶æ€: {pool.get_usage_info()}")

    # æ¸…ç†
    pool.free(new_tensor)
    for i in [1, 3]:
        tensor, size_mb = tensors[i]
        pool.free(tensor)

    print("âœ… ç¢ç‰‡åŒ–æµ‹è¯•é€šè¿‡\n")


def test_kb_allocation():
    """æµ‹è¯•KBçº§åˆ«çš„å†…å­˜åˆ†é…"""
    print("=== æµ‹è¯•KBçº§åˆ«åˆ†é… ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=1)

    # æµ‹è¯•ä¸åŒKBå¤§å°çš„åˆ†é…
    kb_sizes = [512, 1024, 2048, 4096]  # 0.5MB, 1MB, 2MB, 4MB

    for kb in kb_sizes:
        tensor = pool.alloc_kb(kb)
        print(f"åˆ†é… {kb}KB: {tensor.shape}")
        pool.free(tensor)

    print("âœ… KBçº§åˆ«åˆ†é…æµ‹è¯•é€šè¿‡\n")


def test_concurrent_access():
    """æµ‹è¯•å¹¶å‘è®¿é—®"""
    print("=== æµ‹è¯•å¹¶å‘è®¿é—® ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=4)
    results = {"success": 0, "failed": 0}

    def worker(worker_id: int):
        try:
            # æ¯ä¸ªçº¿ç¨‹åˆ†é…å’Œé‡Šæ”¾å¤šä¸ªå†…å­˜å—
            for i in range(5):
                size_mb = random.randint(50, 300)
                tensor = pool.alloc(size_mb)
                time.sleep(random.random() * 0.01)  # å°å»¶è¿Ÿ
                pool.free(tensor)
            results["success"] += 1
        except Exception as e:
            print(f"çº¿ç¨‹ {worker_id} å¤±è´¥: {e}")
            results["failed"] += 1

    # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
    threads = []
    for i in range(10):
        thread = threading.Thread(target=worker, args=(i,))
        threads.append(thread)

    for thread in threads:
        thread.start()

    for thread in threads:
        thread.join()

    print(f"å¹¶å‘æµ‹è¯•ç»“æœ: æˆåŠŸ {results['success']}, å¤±è´¥ {results['failed']}")
    print(f"æœ€ç»ˆçŠ¶æ€: {pool.get_usage_info()}")
    print("âœ… å¹¶å‘è®¿é—®æµ‹è¯•é€šè¿‡\n")


def test_pre_allocated_pool():
    """æµ‹è¯•é¢„åˆ†é…å†…å­˜æ± """
    print("=== æµ‹è¯•é¢„åˆ†é…å†…å­˜æ±  ===")

    # åˆ›å»ºé¢„åˆ†é…æ± 
    prealloc_pool = PreAllocatedPinnedMemoryPool(
        block_shape=(128, 256, 512),  # 128*256*512 = 16M elements
        dtype=torch.bfloat16,
        pool_size=10,
        name="test_prealloc"
    )

    print(f"é¢„åˆ†é…æ± çŠ¶æ€: {prealloc_pool.stats()}")

    # åˆ†é…æ‰€æœ‰é¢„åˆ†é…å—
    allocated_tensors = []
    for i in range(10):
        try:
            tensor = prealloc_pool.allocate()
            allocated_tensors.append(tensor)
            print(f"åˆ†é…é¢„åˆ†é…å— {i}: {tensor.shape}")
        except RuntimeError as e:
            print(f"æ— æ³•åˆ†é…æ›´å¤šé¢„åˆ†é…å—: {e}")
            break

    print(f"æˆåŠŸåˆ†é… {len(allocated_tensors)} ä¸ªé¢„åˆ†é…å—")

    # é‡Šæ”¾ä¸€äº›å—
    for i in range(5):
        tensor = allocated_tensors[i]
        prealloc_pool.free(tensor)
        print(f"é‡Šæ”¾é¢„åˆ†é…å— {i}")

    print(f"é‡Šæ”¾åçŠ¶æ€: {prealloc_pool.stats()}")

    # å°è¯•åˆ†é…è¶…è¿‡é¢„åˆ†é…æ•°é‡
    try:
        extra_tensor = prealloc_pool.allocate()
        print("âŒ é”™è¯¯ï¼šåº”è¯¥æ— æ³•åˆ†é…è¶…è¿‡é¢„åˆ†é…æ•°é‡çš„å—")
    except RuntimeError:
        print("âœ… æ­£ç¡®æ‹’ç»äº†è¶…è¿‡é¢„åˆ†é…æ•°é‡çš„åˆ†é…")

    # æ¸…ç†å‰©ä½™å—
    for tensor in allocated_tensors[5:]:
        prealloc_pool.free(tensor)

    print("âœ… é¢„åˆ†é…å†…å­˜æ± æµ‹è¯•é€šè¿‡\n")


def test_hybrid_pool():
    """æµ‹è¯•æ··åˆå†…å­˜æ± """
    print("=== æµ‹è¯•æ··åˆå†…å­˜æ±  ===")

    # åˆ›å»ºæ··åˆå†…å­˜æ± é…ç½®
    prealloc_configs = [
        {"shape": (64, 128, 256), "pool_size": 5, "name": "small"},
        {"shape": (128, 256, 512), "pool_size": 3, "name": "medium"},
    ]

    hybrid_pool = HybridPinnedMemoryPool(
        prealloc_configs=prealloc_configs,
        dtype=torch.bfloat16,
        max_dynamic_pool_size=1,  # 1GBåŠ¨æ€æ± 
        name="test_hybrid"
    )

    print(f"æ··åˆæ± çŠ¶æ€: {hybrid_pool.stats()}")

    # æµ‹è¯•é¢„åˆ†é…æ± åˆ†é…
    small_tensors = []
    for i in range(5):
        tensor = hybrid_pool.allocate((64, 128, 256))
        small_tensors.append(tensor)
        print(f"ä»é¢„åˆ†é…å°æ± åˆ†é…: {tensor.shape}")

    # æµ‹è¯•åŠ¨æ€åˆ†é…
    dynamic_tensor = hybrid_pool.allocate((200, 300, 400))
    print(f"ä»åŠ¨æ€æ± åˆ†é…: {dynamic_tensor.shape}")

    # é‡Šæ”¾æ‰€æœ‰
    for tensor in small_tensors:
        hybrid_pool.free(tensor)
    hybrid_pool.free(dynamic_tensor)

    print("âœ… æ··åˆå†…å­˜æ± æµ‹è¯•é€šè¿‡\n")


def test_memory_efficiency():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æ•ˆç‡"""
    print("=== æµ‹è¯•å†…å­˜ä½¿ç”¨æ•ˆç‡ ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=2)

    # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
    initial_usage = pool.get_usage_info()

    # è¿›è¡Œå¤šæ¬¡åˆ†é…å’Œé‡Šæ”¾
    for round in range(3):
        print(f"ç¬¬ {round + 1} è½®æµ‹è¯•")
        tensors = []

        # åˆ†é…é˜¶æ®µ
        for i in range(5):
            size_mb = random.randint(100, 400)
            tensor = pool.alloc(size_mb)
            tensors.append((tensor, size_mb))

        print(f"  åˆ†é…åçŠ¶æ€: {pool.get_usage_info()}")

        # é‡Šæ”¾é˜¶æ®µ
        for i, (tensor, size_mb) in enumerate(tensors):
            pool.free(tensor)

        print(f"  é‡Šæ”¾åçŠ¶æ€: {pool.get_usage_info()}")

    final_usage = pool.get_usage_info()
    print(f"æ•ˆç‡æµ‹è¯•å®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {final_usage}")
    print("âœ… å†…å­˜æ•ˆç‡æµ‹è¯•é€šè¿‡\n")


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("=== æµ‹è¯•é”™è¯¯å¤„ç† ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=1)

    # æµ‹è¯•æ— æ•ˆåˆ†é…å¤§å°
    try:
        pool.alloc(0)
        print("âŒ é”™è¯¯ï¼šåº”è¯¥æ‹’ç»0å¤§å°åˆ†é…")
    except ValueError:
        print("âœ… æ­£ç¡®æ‹’ç»äº†0å¤§å°åˆ†é…")

    try:
        pool.alloc(-1)
        print("âŒ é”™è¯¯ï¼šåº”è¯¥æ‹’ç»è´Ÿæ•°å¤§å°åˆ†é…")
    except ValueError:
        print("âœ… æ­£ç¡®æ‹’ç»äº†è´Ÿæ•°å¤§å°åˆ†é…")

    # æµ‹è¯•é‡Šæ”¾æœªåˆ†é…çš„å†…å­˜
    fake_tensor = torch.empty(100, dtype=torch.bfloat16, pin_memory=True)
    try:
        pool.free(fake_tensor)
        print("âœ… æ­£ç¡®å¤„ç†äº†é‡Šæ”¾æœªåˆ†é…å†…å­˜çš„æƒ…å†µ")
    except ValueError:
        print("âŒ é”™è¯¯ï¼šåº”è¯¥ä¼˜é›…å¤„ç†æœªåˆ†é…å†…å­˜çš„é‡Šæ”¾")

    print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡\n")


def performance_test():
    """æ€§èƒ½æµ‹è¯•"""
    print("=== æ€§èƒ½æµ‹è¯• ===")

    pool = PinnedMemoryPool(dtype=torch.bfloat16, pool_size=3)

    # æµ‹è¯•å¤§é‡å°åˆ†é…
    start_time = time.time()
    small_tensors = []

    for i in range(100):
        tensor = pool.alloc(10)  # 10MB
        small_tensors.append(tensor)

    alloc_time = time.time() - start_time
    print(f"100æ¬¡10MBåˆ†é…è€—æ—¶: {alloc_time:.3f}ç§’")
    start_time = time.time()
    for tensor in small_tensors:
        pool.free(tensor)

    free_time = time.time() - start_time
    print(f"100æ¬¡é‡Šæ”¾è€—æ—¶: {free_time:.3f}ç§’")
    print("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡\n")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹PinnedMemoryPoolå…¨é¢æµ‹è¯•\n")

    try:
        test_basic_allocation()
        test_chunk_boundary()
        test_fragmentation()
        test_kb_allocation()
        test_concurrent_access()
        test_pre_allocated_pool()
        test_hybrid_pool()
        test_memory_efficiency()
        test_error_handling()
        performance_test()

        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼PinnedMemoryPoolå·¥ä½œæ­£å¸¸ã€‚")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
